scale_y_continuous(limits = c(0, 1)) +
labs(
title = "Success Rate by AI Initiation",
x = "Condition",
y = "Success Rate"
) +
theme_minimal()
p
ggsave("plots/Success_Rate_by_AI_Initiation_combined.png", plot = p, width = 8, height = 3, dpi = 300, bg = "white")
analyze <- function(successes, failures) {
n <- successes + failures
p <- successes / n
sd <- sqrt(p * (1 - p) / n)
ci_low <- p - 1.96 * sd
ci_high <- p + 1.96 * sd
return(list(
success_rate = p,
sd = sd,
ci_95 = c(ci_low, ci_high)
))
}
library(Hmisc)
analyse_wilson_Confidence <- function(successes, failures) {
n <- successes + failures
p <- successes / n
sd <- sqrt(p * (1 - p) / n)
ci <- binconf(x = successes, n = successes+failures, method = "wilson")
return(list(
success_rate = p,
sd = sd,
ci_lower = ci[2],
ci_upper = ci[3]
))
}
successes <- c(
sum(all_data$Success[all_data$AI_Initiates == TRUE]),
sum(all_data$Success[all_data$AI_Initiates == FALSE]),
sum(all_data$Success[all_data$AI_Initiates == FALSE & all_data$Asks_for_Help == FALSE]),
sum(all_data$Success[all_data$AI_Initiates == FALSE]) - sum(all_data$Success[all_data$AI_Initiates == FALSE & all_data$Asks_for_Help == TRUE])
)
failures <- c(
sum(all_data$Failure[all_data$AI_Initiates == TRUE]),
sum(all_data$Failure[all_data$AI_Initiates == FALSE]),
sum(all_data$Failure[all_data$AI_Initiates == FALSE & all_data$Asks_for_Help == FALSE]),
sum(all_data$Failure[all_data$AI_Initiates == FALSE]) +
sum(all_data$Success[all_data$Asks_for_Help == 1])
)
# Create analyzed results
ai_result <- analyse_wilson_Confidence(successes[1], failures[1])
user_result <- analyse_wilson_Confidence(successes[2], failures[2])
noASK_result <- analyse_wilson_Confidence(successes[3], failures[3])
ask_failing_result <- analyse_wilson_Confidence(successes[4], failures[4])
results_df <- data.frame(
Group = c("AI Initiated", "User Initiated", "w/o Asked for Help", "Asking is failing"),
Success_Rate = c(ai_result$success_rate, user_result$success_rate,
noASK_result$success_rate, ask_failing_result$success_rate),
CI_Low = c(ai_result$ci_lower, user_result$ci_lower,
noASK_result$ci_lower, ask_failing_result$ci_lower),
CI_High = c(ai_result$ci_upper, user_result$ci_upper,
noASK_result$ci_upper, ask_failing_result$ci_upper)
)
# Run Fisher's exact tests
pvals <- c(
fisher.test(matrix(c(successes[1], failures[1], successes[2], failures[2]), nrow = 2))$p.value,
fisher.test(matrix(c(successes[1], failures[1], successes[3], failures[3]), nrow = 2))$p.value,
fisher.test(matrix(c(successes[1], failures[1], successes[4], failures[4]), nrow = 2))$p.value
)
fisher.test(matrix(c(successes[1], failures[1], successes[2], failures[2]), nrow = 2))
# Format p-values for plotting
p_labels <- c("",
paste0("p = ", signif(pvals[1], 3)),
paste0("p = ", signif(pvals[2], 3)),
paste0("p = ", signif(pvals[3], 3)))
results_df$p_label <- p_labels
results_df
# Reorder rows manually: 1, 2, 4, 3
results_df <- results_df[c(1, 2, 3, 4), ]
results_df$Group <- factor(results_df$Group, levels = results_df$Group)
p <- ggplot(results_df, aes(x = Group, y = Success_Rate)) +
geom_point(size = 3) +
geom_errorbar(aes(ymin = CI_Low, ymax = CI_High), width = 0.15) +
geom_text(aes(label = p_label, y = Success_Rate + 0.05), size = 3, vjust = -2) +
geom_hline(yintercept = 0.5, linetype = "solid", color = "red", size = 1.2)+
scale_y_continuous(limits = c(0, 1)) +
labs(
title = "Success Rate by AI Initiation",
x = "Condition",
y = "Success Rate"
) +
theme_minimal()
p
ggsave("plots/Success_Rate_by_AI_Initiation_combined.png", plot = p, width = 8, height = 3, dpi = 300, bg = "white")
analyze <- function(successes, failures) {
n <- successes + failures
p <- successes / n
sd <- sqrt(p * (1 - p) / n)
ci_low <- p - 1.96 * sd
ci_high <- p + 1.96 * sd
return(list(
success_rate = p,
sd = sd,
ci_95 = c(ci_low, ci_high)
))
}
library(Hmisc)
analyse_wilson_Confidence <- function(successes, failures) {
n <- successes + failures
p <- successes / n
sd <- sqrt(p * (1 - p) / n)
ci <- binconf(x = successes, n = successes+failures, method = "wilson")
return(list(
success_rate = p,
sd = sd,
ci_lower = ci[2],
ci_upper = ci[3]
))
}
successes <- c(
sum(all_data$Success[all_data$AI_Initiates == TRUE]),
sum(all_data$Success[all_data$AI_Initiates == FALSE]),
sum(all_data$Success[all_data$AI_Initiates == FALSE & all_data$Asks_for_Help == FALSE]),
sum(all_data$Success[all_data$AI_Initiates == FALSE]) - sum(all_data$Success[all_data$AI_Initiates == FALSE & all_data$Asks_for_Help == TRUE])
)
failures <- c(
sum(all_data$Failure[all_data$AI_Initiates == TRUE]),
sum(all_data$Failure[all_data$AI_Initiates == FALSE]),
sum(all_data$Failure[all_data$AI_Initiates == FALSE & all_data$Asks_for_Help == FALSE]),
sum(all_data$Failure[all_data$AI_Initiates == FALSE]) +
sum(all_data$Success[all_data$Asks_for_Help == 1])
)
# Create analyzed results
ai_result <- analyse_wilson_Confidence(successes[1], failures[1])
user_result <- analyse_wilson_Confidence(successes[2], failures[2])
noASK_result <- analyse_wilson_Confidence(successes[3], failures[3])
ask_failing_result <- analyse_wilson_Confidence(successes[4], failures[4])
results_df <- data.frame(
Group = c("AI Initiated", "User Initiated", "w/o Asked for Help", "Asking is failing"),
Success_Rate = c(ai_result$success_rate, user_result$success_rate,
noASK_result$success_rate, ask_failing_result$success_rate),
CI_Low = c(ai_result$ci_lower, user_result$ci_lower,
noASK_result$ci_lower, ask_failing_result$ci_lower),
CI_High = c(ai_result$ci_upper, user_result$ci_upper,
noASK_result$ci_upper, ask_failing_result$ci_upper)
)
# Run Fisher's exact tests
pvals <- c(
fisher.test(matrix(c(successes[1], failures[1], successes[2], failures[2]), nrow = 2))$p.value,
fisher.test(matrix(c(successes[1], failures[1], successes[3], failures[3]), nrow = 2))$p.value,
fisher.test(matrix(c(successes[1], failures[1], successes[4], failures[4]), nrow = 2))$p.value
)
fisher.test(matrix(c(successes[1], failures[1], successes[2], failures[2]), nrow = 2))
# Format p-values for plotting
p_labels <- c("",
paste0("p = ", signif(pvals[1], 3)),
paste0("p = ", signif(pvals[2], 3)),
paste0("p = ", signif(pvals[3], 3)))
results_df$p_label <- p_labels
results_df
# Reorder rows manually: 1, 2, 4, 3
results_df <- results_df[c(1, 2, 3, 4), ]
results_df$Group <- factor(results_df$Group, levels = results_df$Group)
p <- ggplot(results_df, aes(x = Group, y = Success_Rate)) +
geom_point(size = 3) +
geom_errorbar(aes(ymin = CI_Low, ymax = CI_High), width = 0.15) +
geom_text(aes(label = p_label, y = Success_Rate + 0.05), size = 3, vjust = -2) +
geom_hline(yintercept = 0.5, linetype = "solid", color = "red", size = 1.2)+
scale_y_continuous(limits = c(0, 1)) +
labs(
title = "Success Rate by AI Initiation",
subtitle = "Fisher's Exact Test p-values using wilsons confidence interval",
x = "Condition",
y = "Success Rate"
) +
theme_minimal()
p
ggsave("plots/Success_Rate_by_AI_Initiation_combined.png", plot = p, width = 8, height = 3, dpi = 300, bg = "white")
analyze <- function(successes, failures) {
n <- successes + failures
p <- successes / n
sd <- sqrt(p * (1 - p) / n)
ci_low <- p - 1.96 * sd
ci_high <- p + 1.96 * sd
return(list(
success_rate = p,
sd = sd,
ci_95 = c(ci_low, ci_high)
))
}
library(Hmisc)
analyse_wilson_Confidence <- function(successes, failures) {
n <- successes + failures
p <- successes / n
sd <- sqrt(p * (1 - p) / n)
ci <- binconf(x = successes, n = successes+failures, method = "wilson")
return(list(
success_rate = p,
sd = sd,
ci_lower = ci[2],
ci_upper = ci[3]
))
}
successes <- c(
sum(all_data$Success[all_data$AI_Initiates == TRUE]),
sum(all_data$Success[all_data$AI_Initiates == FALSE]),
sum(all_data$Success[all_data$AI_Initiates == FALSE & all_data$Asks_for_Help == FALSE]),
sum(all_data$Success[all_data$AI_Initiates == FALSE]) - sum(all_data$Success[all_data$AI_Initiates == FALSE & all_data$Asks_for_Help == TRUE])
)
failures <- c(
sum(all_data$Failure[all_data$AI_Initiates == TRUE]),
sum(all_data$Failure[all_data$AI_Initiates == FALSE]),
sum(all_data$Failure[all_data$AI_Initiates == FALSE & all_data$Asks_for_Help == FALSE]),
sum(all_data$Failure[all_data$AI_Initiates == FALSE]) +
sum(all_data$Success[all_data$Asks_for_Help == 1])
)
# Create analyzed results
ai_result <- analyse_wilson_Confidence(successes[1], failures[1])
user_result <- analyse_wilson_Confidence(successes[2], failures[2])
noASK_result <- analyse_wilson_Confidence(successes[3], failures[3])
ask_failing_result <- analyse_wilson_Confidence(successes[4], failures[4])
results_df <- data.frame(
Group = c("AI Initiated", "User Initiated", "w/o Asked for Help", "Asking is failing"),
Success_Rate = c(ai_result$success_rate, user_result$success_rate,
noASK_result$success_rate, ask_failing_result$success_rate),
CI_Low = c(ai_result$ci_lower, user_result$ci_lower,
noASK_result$ci_lower, ask_failing_result$ci_lower),
CI_High = c(ai_result$ci_upper, user_result$ci_upper,
noASK_result$ci_upper, ask_failing_result$ci_upper)
)
# Run Fisher's exact tests
pvals <- c(
fisher.test(matrix(c(successes[1], failures[1], successes[2], failures[2]), nrow = 2))$p.value,
fisher.test(matrix(c(successes[1], failures[1], successes[3], failures[3]), nrow = 2))$p.value,
fisher.test(matrix(c(successes[1], failures[1], successes[4], failures[4]), nrow = 2))$p.value
)
fisher.test(matrix(c(successes[1], failures[1], successes[2], failures[2]), nrow = 2))
# Format p-values for plotting
p_labels <- c("",
paste0("p = ", signif(pvals[1], 3)),
paste0("p = ", signif(pvals[2], 3)),
paste0("p = ", signif(pvals[3], 3)))
results_df$p_label <- p_labels
results_df
# Reorder rows manually: 1, 2, 4, 3
results_df <- results_df[c(1, 2, 3, 4), ]
results_df$Group <- factor(results_df$Group, levels = results_df$Group)
p <- ggplot(results_df, aes(x = Group, y = Success_Rate)) +
geom_point(size = 3) +
geom_errorbar(aes(ymin = CI_Low, ymax = CI_High), width = 0.15) +
geom_text(aes(label = p_label, y = Success_Rate + 0.05), size = 3, vjust = -2) +
geom_hline(yintercept = 0.5, linetype = "solid", color = "red", size = 1.2)+
scale_y_continuous(limits = c(0, 1)) +
labs(
title = "Success Rate by AI Initiation",
subtitle = "Fisher's Exact Test p-values using Wilson score interval",
x = "Condition",
y = "Success Rate"
) +
theme_minimal()
p
ggsave("plots/Success_Rate_by_AI_Initiation_combined.png", plot = p, width = 8, height = 3, dpi = 300, bg = "white")
analyze <- function(successes, failures) {
n <- successes + failures
p <- successes / n
sd <- sqrt(p * (1 - p) / n)
ci_low <- p - 1.96 * sd
ci_high <- p + 1.96 * sd
return(list(
success_rate = p,
sd = sd,
ci_95 = c(ci_low, ci_high)
))
}
library(Hmisc)
analyse_wilson_Confidence <- function(successes, failures) {
n <- successes + failures
p <- successes / n
sd <- sqrt(p * (1 - p) / n)
ci <- binconf(x = successes, n = successes+failures, method = "wilson")
return(list(
success_rate = p,
sd = sd,
ci_lower = ci[2],
ci_upper = ci[3]
))
}
successes <- c(
sum(all_data$Success[all_data$AI_Initiates == TRUE]),
sum(all_data$Success[all_data$AI_Initiates == FALSE]),
sum(all_data$Success[all_data$AI_Initiates == FALSE & all_data$Asks_for_Help == FALSE]),
sum(all_data$Success[all_data$AI_Initiates == FALSE]) - sum(all_data$Success[all_data$AI_Initiates == FALSE & all_data$Asks_for_Help == TRUE])
)
failures <- c(
sum(all_data$Failure[all_data$AI_Initiates == TRUE]),
sum(all_data$Failure[all_data$AI_Initiates == FALSE]),
sum(all_data$Failure[all_data$AI_Initiates == FALSE & all_data$Asks_for_Help == FALSE]),
sum(all_data$Failure[all_data$AI_Initiates == FALSE]) +
sum(all_data$Success[all_data$Asks_for_Help == 1])
)
# Create analyzed results
ai_result <- analyse_wilson_Confidence(successes[1], failures[1])
user_result <- analyse_wilson_Confidence(successes[2], failures[2])
noASK_result <- analyse_wilson_Confidence(successes[3], failures[3])
ask_failing_result <- analyse_wilson_Confidence(successes[4], failures[4])
results_df <- data.frame(
Group = c("AI Initiated", "User Initiated", "w/o Asked for Help", "Asking is failing"),
Success_Rate = c(ai_result$success_rate, user_result$success_rate,
noASK_result$success_rate, ask_failing_result$success_rate),
CI_Low = c(ai_result$ci_lower, user_result$ci_lower,
noASK_result$ci_lower, ask_failing_result$ci_lower),
CI_High = c(ai_result$ci_upper, user_result$ci_upper,
noASK_result$ci_upper, ask_failing_result$ci_upper)
)
# Run Fisher's exact tests
pvals <- c(
fisher.test(matrix(c(successes[1], failures[1], successes[2], failures[2]), nrow = 2))$p.value,
fisher.test(matrix(c(successes[1], failures[1], successes[3], failures[3]), nrow = 2))$p.value,
fisher.test(matrix(c(successes[1], failures[1], successes[4], failures[4]), nrow = 2))$p.value
)
fisher.test(matrix(c(successes[1], failures[1], successes[2], failures[2]), nrow = 2))
# Format p-values for plotting
p_labels <- c("",
paste0("p = ", signif(pvals[1], 3)),
paste0("p = ", signif(pvals[2], 3)),
paste0("p = ", signif(pvals[3], 3)))
results_df$p_label <- p_labels
results_df
# Reorder rows manually: 1, 2, 4, 3
results_df <- results_df[c(1, 2, 3, 4), ]
results_df$Group <- factor(results_df$Group, levels = results_df$Group)
p <- ggplot(results_df, aes(x = Group, y = Success_Rate)) +
geom_point(size = 3) +
geom_errorbar(aes(ymin = CI_Low, ymax = CI_High), width = 0.15) +
geom_text(aes(label = p_label, y = Success_Rate + 0.05), size = 3, vjust = -2) +
geom_hline(yintercept = 0.5, linetype = "solid", color = "red", size = 1.2)+
scale_y_continuous(limits = c(0, 1)) +
labs(
title = "Success Rate by AI Initiation",
subtitle = "Fisher's Exact Test p-values using Wilson score interval",
x = "Condition",
y = "Success Rate"
) +
theme_minimal()
p
ggsave("plots/Success_Rate_by_AI_Initiation_combined.png", plot = p, width = 8, height = 7, dpi = 300, bg = "white")
analyze <- function(successes, failures) {
n <- successes + failures
p <- successes / n
sd <- sqrt(p * (1 - p) / n)
ci_low <- p - 1.96 * sd
ci_high <- p + 1.96 * sd
return(list(
success_rate = p,
sd = sd,
ci_95 = c(ci_low, ci_high)
))
}
library(Hmisc)
analyse_wilson_Confidence <- function(successes, failures) {
n <- successes + failures
p <- successes / n
sd <- sqrt(p * (1 - p) / n)
ci <- binconf(x = successes, n = successes+failures, method = "wilson")
return(list(
success_rate = p,
sd = sd,
ci_lower = ci[2],
ci_upper = ci[3]
))
}
successes <- c(
sum(all_data$Success[all_data$AI_Initiates == TRUE]),
sum(all_data$Success[all_data$AI_Initiates == FALSE]),
sum(all_data$Success[all_data$AI_Initiates == FALSE & all_data$Asks_for_Help == FALSE]),
sum(all_data$Success[all_data$AI_Initiates == FALSE]) - sum(all_data$Success[all_data$AI_Initiates == FALSE & all_data$Asks_for_Help == TRUE])
)
failures <- c(
sum(all_data$Failure[all_data$AI_Initiates == TRUE]),
sum(all_data$Failure[all_data$AI_Initiates == FALSE]),
sum(all_data$Failure[all_data$AI_Initiates == FALSE & all_data$Asks_for_Help == FALSE]),
sum(all_data$Failure[all_data$AI_Initiates == FALSE]) +
sum(all_data$Success[all_data$Asks_for_Help == 1])
)
# Create analyzed results
ai_result <- analyse_wilson_Confidence(successes[1], failures[1])
user_result <- analyse_wilson_Confidence(successes[2], failures[2])
noASK_result <- analyse_wilson_Confidence(successes[3], failures[3])
ask_failing_result <- analyse_wilson_Confidence(successes[4], failures[4])
results_df <- data.frame(
Group = c("AI Initiated", "User Initiated", "w/o Asked for Help", "Asking is failing"),
Success_Rate = c(ai_result$success_rate, user_result$success_rate,
noASK_result$success_rate, ask_failing_result$success_rate),
CI_Low = c(ai_result$ci_lower, user_result$ci_lower,
noASK_result$ci_lower, ask_failing_result$ci_lower),
CI_High = c(ai_result$ci_upper, user_result$ci_upper,
noASK_result$ci_upper, ask_failing_result$ci_upper)
)
# Run Fisher's exact tests
pvals <- c(
fisher.test(matrix(c(successes[1], failures[1], successes[2], failures[2]), nrow = 2))$p.value,
fisher.test(matrix(c(successes[1], failures[1], successes[3], failures[3]), nrow = 2))$p.value,
fisher.test(matrix(c(successes[1], failures[1], successes[4], failures[4]), nrow = 2))$p.value
)
fisher.test(matrix(c(successes[1], failures[1], successes[2], failures[2]), nrow = 2))
# Format p-values for plotting
p_labels <- c("",
paste0("p = ", signif(pvals[1], 3)),
paste0("p = ", signif(pvals[2], 3)),
paste0("p = ", signif(pvals[3], 3)))
results_df$p_label <- p_labels
results_df
# Reorder rows manually: 1, 2, 4, 3
results_df <- results_df[c(1, 2, 3, 4), ]
results_df$Group <- factor(results_df$Group, levels = results_df$Group)
p <- ggplot(results_df, aes(x = Group, y = Success_Rate)) +
geom_point(size = 3) +
geom_errorbar(aes(ymin = CI_Low, ymax = CI_High), width = 0.15) +
geom_text(aes(label = p_label, y = Success_Rate + 0.05), size = 3, vjust = -5) +
geom_hline(yintercept = 0.5, linetype = "solid", color = "red", size = 1.2)+
scale_y_continuous(limits = c(0, 1)) +
labs(
title = "Success Rate by AI Initiation",
subtitle = "Fisher's Exact Test p-values using Wilson score interval",
x = "Condition",
y = "Success Rate"
) +
theme_minimal()
p
ggsave("plots/Success_Rate_by_AI_Initiation_combined.png", plot = p, width = 8, height = 7, dpi = 300, bg = "white")
analyze <- function(successes, failures) {
n <- successes + failures
p <- successes / n
sd <- sqrt(p * (1 - p) / n)
ci_low <- p - 1.96 * sd
ci_high <- p + 1.96 * sd
return(list(
success_rate = p,
sd = sd,
ci_95 = c(ci_low, ci_high)
))
}
library(Hmisc)
analyse_wilson_Confidence <- function(successes, failures) {
n <- successes + failures
p <- successes / n
sd <- sqrt(p * (1 - p) / n)
ci <- binconf(x = successes, n = successes+failures, method = "wilson")
return(list(
success_rate = p,
sd = sd,
ci_lower = ci[2],
ci_upper = ci[3]
))
}
successes <- c(
sum(all_data$Success[all_data$AI_Initiates == TRUE]),
sum(all_data$Success[all_data$AI_Initiates == FALSE]),
sum(all_data$Success[all_data$AI_Initiates == FALSE & all_data$Asks_for_Help == FALSE]),
sum(all_data$Success[all_data$AI_Initiates == FALSE]) - sum(all_data$Success[all_data$AI_Initiates == FALSE & all_data$Asks_for_Help == TRUE])
)
failures <- c(
sum(all_data$Failure[all_data$AI_Initiates == TRUE]),
sum(all_data$Failure[all_data$AI_Initiates == FALSE]),
sum(all_data$Failure[all_data$AI_Initiates == FALSE & all_data$Asks_for_Help == FALSE]),
sum(all_data$Failure[all_data$AI_Initiates == FALSE]) +
sum(all_data$Success[all_data$Asks_for_Help == 1])
)
# Create analyzed results
ai_result <- analyse_wilson_Confidence(successes[1], failures[1])
user_result <- analyse_wilson_Confidence(successes[2], failures[2])
noASK_result <- analyse_wilson_Confidence(successes[3], failures[3])
ask_failing_result <- analyse_wilson_Confidence(successes[4], failures[4])
results_df <- data.frame(
Group = c("AI Initiated", "User Initiated", "w/o Asked for Help", "Asking is failing"),
Success_Rate = c(ai_result$success_rate, user_result$success_rate,
noASK_result$success_rate, ask_failing_result$success_rate),
CI_Low = c(ai_result$ci_lower, user_result$ci_lower,
noASK_result$ci_lower, ask_failing_result$ci_lower),
CI_High = c(ai_result$ci_upper, user_result$ci_upper,
noASK_result$ci_upper, ask_failing_result$ci_upper)
)
# Run Fisher's exact tests
pvals <- c(
fisher.test(matrix(c(successes[1], failures[1], successes[2], failures[2]), nrow = 2))$p.value,
fisher.test(matrix(c(successes[1], failures[1], successes[3], failures[3]), nrow = 2))$p.value,
fisher.test(matrix(c(successes[1], failures[1], successes[4], failures[4]), nrow = 2))$p.value
)
fisher.test(matrix(c(successes[1], failures[1], successes[2], failures[2]), nrow = 2))
# Format p-values for plotting
p_labels <- c("",
paste0("p = ", signif(pvals[1], 3)),
paste0("p = ", signif(pvals[2], 3)),
paste0("p = ", signif(pvals[3], 3)))
results_df$p_label <- p_labels
results_df
# Reorder rows manually: 1, 2, 4, 3
results_df <- results_df[c(1, 2, 3, 4), ]
results_df$Group <- factor(results_df$Group, levels = results_df$Group)
p <- ggplot(results_df, aes(x = Group, y = Success_Rate)) +
geom_point(size = 3) +
geom_errorbar(aes(ymin = CI_Low, ymax = CI_High), width = 0.15) +
geom_text(aes(label = p_label, y = Success_Rate + 0.05), size = 3, vjust = -4) +
geom_hline(yintercept = 0.5, linetype = "solid", color = "red", size = 1.2)+
scale_y_continuous(limits = c(0, 1)) +
labs(
title = "Success Rate by AI Initiation",
subtitle = "Fisher's Exact Test p-values using Wilson score interval",
x = "Condition",
y = "Success Rate"
) +
theme_minimal()
p
ggsave("plots/Success_Rate_by_AI_Initiation_combined.png", plot = p, width = 8, height = 7, dpi = 300, bg = "white")
